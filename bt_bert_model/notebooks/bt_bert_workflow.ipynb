{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "74009af2",
      "metadata": {},
      "source": [
        "# BT-BERT Workflow\n",
        "Bu notebook, BlueSense kozmetik öneri hattındaki tüm önemli adımları tek bir yerden çalıştırmak için hazırlandı. Aşağıdaki bölümler sırayla veri kümelerini normalleştirir, pseudo-label üretir, modeli değerlendirir ve son olarak hibrit öneri demoları üretir. Her bölümdeki kod hücresinin neden çalıştırıldığı ve hangi dosyaları etkilediği ayrıntılı olarak açıklanmıştır.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a115805e",
      "metadata": {},
      "source": [
        "# 0. Hazırlık\n",
        "Bu bölüm, notebook boyunca tekrar kullanılacak tüm dizin ve konfigürasyon değişkenlerini hazırlar. Kod hücresi proje kökünü, veri klasörlerini ve Dataset_Pipeline paketini `sys.path` içerisine alır; böylece sonraki hücreler modül importlarında sorun yaşamadan doğrudan bu yolları kullanabilir. Ayrıca `CONFIG_PATH`, `DATA_DIR`, `RAW_DATA_DIR` ve ham veri kaynağını temsil eden `DATASET_DIR` gibi kritik yolları gösterecek biçimde ekrana yazdırır.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "f28be014",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-03T14:15:23.547790Z",
          "iopub.status.busy": "2025-11-03T14:15:23.547510Z",
          "iopub.status.idle": "2025-11-03T14:15:23.553661Z",
          "shell.execute_reply": "2025-11-03T14:15:23.552964Z"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Working directory     : c:\\Users\\barut\\OneDrive\\Desktop\\BlueSenseRecommendation\\Recommendation-Systems\\bt_bert_model\\notebooks\n",
            "Repository root       : c:\\Users\\barut\\OneDrive\\Desktop\\BlueSenseRecommendation\\Recommendation-Systems\n",
            "Dataset source dir    : c:\\Users\\barut\\OneDrive\\Desktop\\BlueSenseRecommendation\\Recommendation-Systems\\Dataset\n",
            "Pipeline output dir   : c:\\Users\\barut\\OneDrive\\Desktop\\BlueSenseRecommendation\\Recommendation-Systems\\bt_bert_model\\data\\raw\n"
          ]
        }
      ],
      "source": [
        "from pathlib import Path\n",
        "import subprocess\n",
        "import sys\n",
        "\n",
        "SEARCH_PATHS = [Path.cwd(), Path.cwd().parent, Path.cwd().parent.parent]\n",
        "for candidate in SEARCH_PATHS:\n",
        "    if (candidate / 'bt_bert_model').exists() and (candidate / 'Dataset_Pipeline').exists():\n",
        "        REPO_ROOT = candidate\n",
        "        break\n",
        "else:\n",
        "    raise RuntimeError('Repository root could not be located relative to the notebook.')\n",
        "\n",
        "PROJECT_ROOT = REPO_ROOT / 'bt_bert_model'\n",
        "DATASET_PIPELINE_ROOT = REPO_ROOT / 'Dataset_Pipeline'\n",
        "SERVICE_ROOT = REPO_ROOT / 'service'\n",
        "DATA_DIR = PROJECT_ROOT / 'data'\n",
        "RAW_DATA_DIR = DATA_DIR / 'raw'\n",
        "DATASET_DIR = REPO_ROOT / 'Dataset'\n",
        "for path in (REPO_ROOT, PROJECT_ROOT, DATASET_PIPELINE_ROOT, SERVICE_ROOT):\n",
        "    if path.exists() and str(path) not in sys.path:\n",
        "        sys.path.append(str(path))\n",
        "\n",
        "CONFIG_PATH = PROJECT_ROOT / 'config.yaml'\n",
        "print(f'Working directory     : {Path.cwd()}')\n",
        "print(f'Repository root       : {REPO_ROOT}')\n",
        "print(f'Dataset source dir    : {DATASET_DIR}')\n",
        "print(f'Pipeline output dir   : {RAW_DATA_DIR}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "94c2508b",
      "metadata": {},
      "source": [
        "# 1. Dataset Pipeline\n",
        "Bu adım ham EWG kategori CSV dosyalarını ingest eder, kolonları hizalar, ürün kimliklerini yeniden oluşturur ve normalize edilmiş ingredient listelerini çıkarır. `Dataset_Pipeline.data_pipeline.run_pipeline` fonksiyonu çalıştırılarak: (1) `Dataset/` klasöründeki tüm dosyalar okunur, (2) kategori ve ingredient değerleri normalize edilir, (3) çıktı olarak `bt_bert_model/data/raw/` altında `unified_products.csv`, `ingredient_normalisation_map.csv` ve `unique_ingredients.csv` dosyaları üretilir. Kod hücresi ayrıca yürütme süresini raporlar ve ürün tablosunun ilk satırlarını önizleyerek pipeline’ın doğru çalıştığını doğrular.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "6b9b4227",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-03T14:15:23.555203Z",
          "iopub.status.busy": "2025-11-03T14:15:23.555038Z",
          "iopub.status.idle": "2025-11-03T14:15:31.805904Z",
          "shell.execute_reply": "2025-11-03T14:15:31.805344Z"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset pipeline tamamlandı: 0:00:07.864910.\n",
            "Products table size: (16556, 11)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>product_id</th>\n",
              "      <th>name</th>\n",
              "      <th>category</th>\n",
              "      <th>ingredient_count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Grace + Tonic Botanical Beauty Cleansing Mud (...</td>\n",
              "      <td>facial cleanser</td>\n",
              "      <td>24</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Murad Hydration AHA/BHA Exfoliating Cleanser</td>\n",
              "      <td>facial cleanser</td>\n",
              "      <td>21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Purity One Step Mattifying Facial Cleanser</td>\n",
              "      <td>facial cleanser</td>\n",
              "      <td>22</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>Every Man Jack, Skin. Volcanic Clay 2 in 1 Mas...</td>\n",
              "      <td>facial cleanser</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>Pond's Deep Cleanser Make Up Remover Cold Crea...</td>\n",
              "      <td>makeup remover</td>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   product_id                                               name  \\\n",
              "0           0  Grace + Tonic Botanical Beauty Cleansing Mud (...   \n",
              "1           1       Murad Hydration AHA/BHA Exfoliating Cleanser   \n",
              "2           2         Purity One Step Mattifying Facial Cleanser   \n",
              "3           3  Every Man Jack, Skin. Volcanic Clay 2 in 1 Mas...   \n",
              "4           4  Pond's Deep Cleanser Make Up Remover Cold Crea...   \n",
              "\n",
              "          category  ingredient_count  \n",
              "0  facial cleanser                24  \n",
              "1  facial cleanser                21  \n",
              "2  facial cleanser                22  \n",
              "3  facial cleanser                10  \n",
              "4   makeup remover                13  "
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import importlib.util\n",
        "from datetime import datetime\n",
        "\n",
        "module_path = DATASET_PIPELINE_ROOT / 'data_pipeline.py'\n",
        "if not module_path.exists():\n",
        "    raise FileNotFoundError(f'Dataset pipeline module not found at {module_path}')\n",
        "spec = importlib.util.spec_from_file_location('dataset_pipeline', module_path)\n",
        "data_pipeline = importlib.util.module_from_spec(spec)\n",
        "spec.loader.exec_module(data_pipeline)\n",
        "\n",
        "pipeline_start = datetime.now()\n",
        "pipeline_outputs = data_pipeline.run_pipeline(DATASET_DIR, RAW_DATA_DIR)\n",
        "elapsed = datetime.now() - pipeline_start\n",
        "print(f'Dataset pipeline tamamlandı: {elapsed}.')\n",
        "print(f'Products table size: {pipeline_outputs.products.shape}')\n",
        "\n",
        "preview_cols = ['product_id', 'name', 'category', 'ingredient_count']\n",
        "available_cols = [col for col in preview_cols if col in pipeline_outputs.products.columns]\n",
        "preview = pipeline_outputs.products.head()[available_cols]\n",
        "preview\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d74ff118",
      "metadata": {},
      "source": [
        "# 2. Data Labelling\n",
        "Pipeline çıktılarının ardından bu adım pseudo-label üretim sürecini otomatikleştirir. Hücre, `src/data_prep.py` betiğini aynı Python süreç içinde çalıştırır; konfigürasyon olarak `bt_bert_model/config.yaml` kullanılır. İşlem sonucunda `bt_bert_model/data/` dizininde `labels.csv`, `train.csv`, `val.csv` ve `test.csv` dosyaları güncellenir. Kod her dosyanın varlığını kontrol edip durumunu ekrana yazdırır; böylece veri hazırlama aşamasının başarılı şekilde tamamlandığı doğrulanır.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "7b091078",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-03T14:15:31.807797Z",
          "iopub.status.busy": "2025-11-03T14:15:31.807554Z",
          "iopub.status.idle": "2025-11-03T14:15:36.017897Z",
          "shell.execute_reply": "2025-11-03T14:15:36.017316Z"
        }
      },
      "outputs": [],
      "source": [
        "# import os\n",
        "# import subprocess\n",
        "# import sys\n",
        "\n",
        "# data_prep_cmd = [\n",
        "#     sys.executable,\n",
        "#     str(PROJECT_ROOT / 'src' / 'data_prep.py'),\n",
        "#     '--config',\n",
        "#     str(CONFIG_PATH),\n",
        "# ]\n",
        "# env = os.environ.copy()\n",
        "# py_path_entries = [str(REPO_ROOT), str(PROJECT_ROOT), str(DATASET_PIPELINE_ROOT)]\n",
        "# existing_py_path = env.get('PYTHONPATH', '')\n",
        "# combined_py_path = os.pathsep.join([entry for entry in py_path_entries if entry] + ([existing_py_path] if existing_py_path else []))\n",
        "# env['PYTHONPATH'] = combined_py_path\n",
        "# print('Running:', ' '.join(str(part) for part in data_prep_cmd))\n",
        "# subprocess.run(data_prep_cmd, check=True, env=env)\n",
        "\n",
        "# required = [\n",
        "#     DATA_DIR / 'labels.csv',\n",
        "#     DATA_DIR / 'train.csv',\n",
        "#     DATA_DIR / 'val.csv',\n",
        "#     DATA_DIR / 'test.csv',\n",
        "# ]\n",
        "# for path in required:\n",
        "#     status = 'OK' if path.exists() else 'MISSING'\n",
        "#     print(f'{path.name}: {status}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "355c2289",
      "metadata": {},
      "source": [
        "# 3. Label Özetini İnceleme\n",
        "`label_summary.json` dosyası, her concern için pozitif/negatif örnek sayısını içerir. Bu hücre dosyayı okuyup okunabilir bir tabloya dönüştürerek label dağılımının dengeli olup olmadığını gözlemlemenizi sağlar. Eksik dosya durumunda kullanıcıyı uyarır ve bir önceki adımı tekrar çalıştırması gerektiğini belirtir.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "106d1fbe",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-03T14:15:36.019703Z",
          "iopub.status.busy": "2025-11-03T14:15:36.019336Z",
          "iopub.status.idle": "2025-11-03T14:15:36.027168Z",
          "shell.execute_reply": "2025-11-03T14:15:36.026512Z"
        }
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>positive</th>\n",
              "      <th>negative</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>acne</th>\n",
              "      <td>7887</td>\n",
              "      <td>8669</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>age</th>\n",
              "      <td>6863</td>\n",
              "      <td>9693</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>eyebag</th>\n",
              "      <td>1558</td>\n",
              "      <td>14998</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>moisture</th>\n",
              "      <td>14393</td>\n",
              "      <td>2163</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>oiliness</th>\n",
              "      <td>7841</td>\n",
              "      <td>8715</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>redness</th>\n",
              "      <td>8023</td>\n",
              "      <td>8533</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>wrinkle</th>\n",
              "      <td>7876</td>\n",
              "      <td>8680</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          positive  negative\n",
              "acne          7887      8669\n",
              "age           6863      9693\n",
              "eyebag        1558     14998\n",
              "moisture     14393      2163\n",
              "oiliness      7841      8715\n",
              "redness       8023      8533\n",
              "wrinkle       7876      8680"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import json\n",
        "\n",
        "summary_path = Path(\"../data/label_summary.json\")\n",
        "if summary_path.exists():\n",
        "    summary = json.loads(summary_path.read_text(encoding=\"utf-8\"))\n",
        "    display(pd.DataFrame(summary).T)\n",
        "else:\n",
        "    print(\"Run the data labelling step first.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "86ef38dd",
      "metadata": {},
      "source": [
        "# 4. Eğitim (Devre Dışı)\n",
        "Bu notebook eğitim hücresini yalnızca referans amaçlı tutuyor; eğitim clustera taşındığı ve güncel model checkpointleri kullanıldığı için kod kısmı yorum satırına alınmıştır.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "2c84ef1c",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "No checkpoints found. Copy from cluster or run a short local test:\n",
            "  python ../src/train.py --config ../config.yaml --max_steps 10\n"
          ]
        }
      ],
      "source": [
        "# Disable local training; use checkpoints copied from cluster.\n",
        "from pathlib import Path\n",
        "ckpt_dir = Path('../outputs/checkpoints')\n",
        "ckpts = sorted(ckpt_dir.glob('*.pt')) if ckpt_dir.exists() else []\n",
        "if ckpts:\n",
        "    print(f'Found {len(ckpts)} checkpoints; skipping training.')\n",
        "else:\n",
        "    print('No checkpoints found. Copy from cluster or run a short local test:')\n",
        "    print('  python ../src/train.py --config ../config.yaml --max_steps 10')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "445ef056",
      "metadata": {},
      "source": [
        "# 5. Değerlendirme\n",
        "Bu bölüm, kayıtlı checkpoint’ler üzerinden `src/evaluate.py` komutunu nasıl çalıştıracağınızı gösterir. Kod mevcut `outputs/checkpoints/` dizininde son kaydedilen modeli bulur, eğer bulunursa değerlendirme komutunu çıktısıyla birlikte çalıştırır ve sonuçların nereye yazıldığını bildirir. Checkpoint yoksa kullanıcıya önce eğitim ya da harici bir checkpoint yerleştirmesi gerektiğini söyler.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "702f5991",
      "metadata": {},
      "source": [
        "## 4b. GPU Eğitim Scripti (Devre Dışı)\n",
        "Tüm eğitim süreçleri clustera taşındığından bu hücre de yorum satırına alınmıştır. Gerekirse `bt_bert_model/scripts/run_gpu_training.py` dosyasını doğrudan çalıştırabilirsiniz.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "cdd579ce",
      "metadata": {
        "tags": [
          "gpu-training"
        ]
      },
      "outputs": [],
      "source": [
        "# from bt_bert_model.scripts.run_gpu_training import main as run_gpu_training_main\n",
        "\n",
        "# try:\n",
        "#     run_gpu_training_main(['--preset', 'debug'])\n",
        "# except SystemExit as exc:\n",
        "#     print(exc)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "f996e953",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-03T14:15:36.028960Z",
          "iopub.status.busy": "2025-11-03T14:15:36.028754Z",
          "iopub.status.idle": "2025-11-03T14:15:36.032802Z",
          "shell.execute_reply": "2025-11-03T14:15:36.032222Z"
        }
      },
      "outputs": [],
      "source": [
        "# from pathlib import Path\n",
        "# import json\n",
        "# import subprocess\n",
        "\n",
        "# checkpoint_dir = Path(\"../outputs/checkpoints\")\n",
        "# checkpoints = sorted(checkpoint_dir.glob(\"*.pt\"))\n",
        "# print(\"Found checkpoints:\")\n",
        "# for ckpt in checkpoints:\n",
        "#     print(ckpt.name)\n",
        "\n",
        "# if checkpoints:\n",
        "#     selected_checkpoint = checkpoints[-1]\n",
        "#     metrics_output = Path(\"../outputs/eval_metrics.json\")\n",
        "#     cmd = [\"python\", \"../src/evaluate.py\", \"--config\", str(CONFIG_PATH), \"--checkpoint\", str(selected_checkpoint), \"--split\", \"test\", \"--output\", str(metrics_output)]\n",
        "#     print('Running:', ' '.join(cmd))\n",
        "#     subprocess.run(cmd, check=True)\n",
        "#     print(json.loads(metrics_output.read_text(encoding='utf-8')))\n",
        "# else:\n",
        "#     print('Train the model first to generate checkpoints.')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "16f187d1",
      "metadata": {},
      "source": [
        "# 6. Açıklanabilirlik\n",
        "Modelin dikkat mekanizmasını analiz etmek için `src/explain.py` betiği kullanılır. Bu hücre, geçerli bir checkpoint bulunduğunda dikkat raporlarının (`outputs/attention_reports/`) nasıl üretileceğini adım adım gösterir. Hiçbir dosya oluşturulmamışsa kullanıcı uygun checkpoint’i temin etmesi için bilgilendirilir.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "b62cf3b9",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-03T14:15:36.034212Z",
          "iopub.status.busy": "2025-11-03T14:15:36.034016Z",
          "iopub.status.idle": "2025-11-03T14:15:36.037847Z",
          "shell.execute_reply": "2025-11-03T14:15:36.037263Z"
        }
      },
      "outputs": [],
      "source": [
        "# from pathlib import Path\n",
        "# import json\n",
        "# import subprocess\n",
        "\n",
        "# explain_output = Path(\"../outputs/attention_reports/explanations.json\")\n",
        "# explain_output.parent.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# if checkpoints:\n",
        "#     selected_checkpoint = checkpoints[-1]\n",
        "#     cmd = [\"python\", \"../src/explain.py\", \"--config\", str(CONFIG_PATH), \"--checkpoint\", str(selected_checkpoint), \"--split\", \"val\", \"--sample\", \"50\", \"--output\", str(explain_output)]\n",
        "#     print('Running:', ' '.join(cmd))\n",
        "#     subprocess.run(cmd, check=True)\n",
        "#     explanations = json.loads(explain_output.read_text(encoding='utf-8'))\n",
        "#     print(f\"{len(explanations)} explanations written to {explain_output}\")\n",
        "# else:\n",
        "#     print('No checkpoints available. Train the model first.')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fe0bd7f5",
      "metadata": {},
      "source": [
        "# 7. Çıktıları İnceleme\n",
        "Eğitim veya değerlendirme sonrası üretilen `bt_bert_outputs.csv` dosyası model tahminlerini içerir. Hücre, dosya mevcut değilse otomatik olarak `src/predict.py` betiğini çağırarak en güncel checkpoint ile tahmin üretir; dosya varsa ilk birkaç satırı görüntüleyerek model skorlarının incelemesini kolaylaştırır.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "54a8556a",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-03T14:15:36.039258Z",
          "iopub.status.busy": "2025-11-03T14:15:36.039061Z",
          "iopub.status.idle": "2025-11-03T14:15:36.043025Z",
          "shell.execute_reply": "2025-11-03T14:15:36.042428Z"
        }
      },
      "outputs": [],
      "source": [
        "# import pandas as pd\n",
        "# from pathlib import Path\n",
        "# import subprocess\n",
        "\n",
        "# output_path = Path('../outputs/bt_bert_outputs.csv')\n",
        "# if not output_path.exists():\n",
        "#     print('Creating prediction output using latest checkpoint...')\n",
        "#     checkpoint_dir = Path('../outputs/checkpoints')\n",
        "#     checkpoints = sorted(checkpoint_dir.glob('*.pt'))\n",
        "#     if checkpoints:\n",
        "#         selected_checkpoint = checkpoints[-1]\n",
        "#         cmd = [\n",
        "#             'python',\n",
        "#             '../src/predict.py',\n",
        "#             '--config',\n",
        "#             str(CONFIG_PATH),\n",
        "#             '--checkpoint',\n",
        "#             str(selected_checkpoint),\n",
        "#             '--split',\n",
        "#             'test',\n",
        "#             '--output',\n",
        "#             str(output_path),\n",
        "#         ]\n",
        "#         print('Running:', ' '.join(cmd))\n",
        "#         subprocess.run(cmd, check=True)\n",
        "#     else:\n",
        "#         print('No checkpoints available. Train the model first.')\n",
        "\n",
        "# if output_path.exists():\n",
        "#     df = pd.read_csv(output_path)\n",
        "#     display(df.head())\n",
        "# else:\n",
        "#     print('No exported recommendation outputs yet.')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4423d4b1",
      "metadata": {},
      "source": [
        "---\n",
        "Bu notebook, veriyi ham halinden normalize edilmiş formata dönüştürmekten, pseudo-label üretimine, model çıktılarının doğrulanmasına ve hibrit tavsiye demosuna kadar uzanan uçtan uca bir çalışma akışı sunar. Her bölümün açıklamalarında hangi dosyaların okunduğu/yazıldığı ve komutların ne yaptığı detaylı biçimde yer almaktadır.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "714f5af5",
      "metadata": {},
      "source": [
        "## 8. Recommendation Demo\n",
        "Bu bölüm, Hybrid Concern deneylerinden elde edilen `product_concern_weights.csv` dosyasını kullanarak profil bazlı önerilerin nasıl üretileceğini gösterir. İlk hücre hibrit öneri sınıfını ve örnek kullanıcı profillerini yükler; ikinci hücre seçilen demo kullanıcılarının concern vektörlerini alır, `HybridRecommender` ile ürünleri skorlar ve her öneri için hibrit puanı ile model olasılıklarını satır satır ekrana yazar. Böylece gerçek bir kullanıcı metadatası geldiğinde servisin nasıl davranacağı notebook üzerinden görülür.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "45e16373",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-03T14:15:36.044541Z",
          "iopub.status.busy": "2025-11-03T14:15:36.044339Z",
          "iopub.status.idle": "2025-11-03T14:15:36.290482Z",
          "shell.execute_reply": "2025-11-03T14:15:36.289882Z"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hibrit ağırlık dosyası: c:\\Users\\barut\\OneDrive\\Desktop\\BlueSenseRecommendation\\Recommendation-Systems\\Experiments\\Hybrid_Concern_Test\\product_concern_weights.csv\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "['focused_acne',\n",
              " 'focused_age',\n",
              " 'focused_eyebag',\n",
              " 'focused_moisture',\n",
              " 'focused_oiliness']"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from service.hybrid_recommender import HybridRecommender, load_demo_profiles\n",
        "\n",
        "weights_path = REPO_ROOT / 'Experiments' / 'Hybrid_Concern_Test' / 'product_concern_weights.csv'\n",
        "print(f'Hibrit ağırlık dosyası: {weights_path}')\n",
        "hybrid = HybridRecommender(weights_path=weights_path)\n",
        "demo_profiles = load_demo_profiles()\n",
        "sorted(demo_profiles.keys())[:5]  # profillerin bir kısmını göster\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
