{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "74009af2",
   "metadata": {},
   "source": [
    "# BT-BERT Workflow\n",
    "\n",
    "Bu notebook BT-BERT veri hazırlığı, eğitim, değerlendirme ve açıklanabilirlik adımlarını uçtan uca çalıştırmak için başlangıç noktasıdır."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a115805e",
   "metadata": {},
   "source": [
    "# 1. Hazirlik"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f28be014",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import json\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "PROJECT_ROOT = Path('..').resolve()\n",
    "if str(PROJECT_ROOT) not in sys.path:\n",
    "    sys.path.append(str(PROJECT_ROOT))\n",
    "\n",
    "CONFIG_PATH = PROJECT_ROOT / 'config.yaml'\n",
    "\n",
    "# NOTE: adjust environment variables (e.g., CUDA) here if needed.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d74ff118",
   "metadata": {},
   "source": [
    "# 2. Data Labelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b091078",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Skip data labelling locally; expect files copied from cluster.\n",
    "from pathlib import Path\n",
    "data_dir = Path('../data')\n",
    "required = [data_dir/'labels.csv', data_dir/'train.csv', data_dir/'val.csv', data_dir/'test.csv']\n",
    "missing = [p for p in required if not p.exists()]\n",
    "if missing:\n",
    "    print('Data files missing. Copy from cluster or run data_prep manually:')\n",
    "    print('  python ../src/data_prep.py --config ../config.yaml')\n",
    "    print('Missing:', [str(p) for p in missing])\n",
    "else:\n",
    "    print('Data files present; skipping labelling step.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "355c2289",
   "metadata": {},
   "source": [
    "# 3. Inspect Label Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "106d1fbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run the data labelling step first.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "summary_path = Path(\"../data/label_summary.json\")\n",
    "if summary_path.exists():\n",
    "    summary = json.loads(summary_path.read_text(encoding=\"utf-8\"))\n",
    "    display(pd.DataFrame(summary).T)\n",
    "else:\n",
    "    print(\"Run the data labelling step first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86ef38dd",
   "metadata": {},
   "source": [
    "# 4. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2c84ef1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Disable local training; use checkpoints copied from cluster.\n",
    "from pathlib import Path\n",
    "ckpt_dir = Path('../outputs/checkpoints')\n",
    "ckpts = sorted(ckpt_dir.glob('*.pt')) if ckpt_dir.exists() else []\n",
    "if ckpts:\n",
    "    print(f'Found {len(ckpts)} checkpoints; skipping training.')\n",
    "else:\n",
    "    print('No checkpoints found. Copy from cluster or run a short local test:')\n",
    "    print('  python ../src/train.py --config ../config.yaml --max_steps 10')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "445ef056",
   "metadata": {},
   "source": [
    "# 5. Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f996e953",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found checkpoints:\n",
      "Train the model first to generate checkpoints.\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import json\n",
    "import subprocess\n",
    "\n",
    "checkpoint_dir = Path(\"../outputs/checkpoints\")\n",
    "checkpoints = sorted(checkpoint_dir.glob(\"*.pt\"))\n",
    "print(\"Found checkpoints:\")\n",
    "for ckpt in checkpoints:\n",
    "    print(ckpt.name)\n",
    "\n",
    "if checkpoints:\n",
    "    selected_checkpoint = checkpoints[-1]\n",
    "    metrics_output = Path(\"../outputs/eval_metrics.json\")\n",
    "    cmd = [\"python\", \"../src/evaluate.py\", \"--config\", str(CONFIG_PATH), \"--checkpoint\", str(selected_checkpoint), \"--split\", \"test\", \"--output\", str(metrics_output)]\n",
    "    print('Running:', ' '.join(cmd))\n",
    "    subprocess.run(cmd, check=True)\n",
    "    print(json.loads(metrics_output.read_text(encoding='utf-8')))\n",
    "else:\n",
    "    print('Train the model first to generate checkpoints.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16f187d1",
   "metadata": {},
   "source": [
    "# 6. Explainability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b62cf3b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import json\n",
    "import subprocess\n",
    "\n",
    "explain_output = Path(\"../outputs/attention_reports/explanations.json\")\n",
    "explain_output.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "if checkpoints:\n",
    "    selected_checkpoint = checkpoints[-1]\n",
    "    cmd = [\"python\", \"../src/explain.py\", \"--config\", str(CONFIG_PATH), \"--checkpoint\", str(selected_checkpoint), \"--split\", \"val\", \"--sample\", \"50\", \"--output\", str(explain_output)]\n",
    "    print('Running:', ' '.join(cmd))\n",
    "    subprocess.run(cmd, check=True)\n",
    "    explanations = json.loads(explain_output.read_text(encoding='utf-8'))\n",
    "    print(f\"{len(explanations)} explanations written to {explain_output}\")\n",
    "else:\n",
    "    print('No checkpoints available. Train the model first.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe0bd7f5",
   "metadata": {},
   "source": [
    "# 7. Inspect Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "54a8556a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating prediction output using latest checkpoint...\n",
      "No checkpoints available. Train the model first.\n",
      "No exported recommendation outputs yet.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import subprocess\n",
    "\n",
    "output_path = Path('../outputs/bt_bert_outputs.csv')\n",
    "if not output_path.exists():\n",
    "    print('Creating prediction output using latest checkpoint...')\n",
    "    checkpoint_dir = Path('../outputs/checkpoints')\n",
    "    checkpoints = sorted(checkpoint_dir.glob('*.pt'))\n",
    "    if checkpoints:\n",
    "        selected_checkpoint = checkpoints[-1]\n",
    "        cmd = [\n",
    "            'python',\n",
    "            '../src/predict.py',\n",
    "            '--config',\n",
    "            str(CONFIG_PATH),\n",
    "            '--checkpoint',\n",
    "            str(selected_checkpoint),\n",
    "            '--split',\n",
    "            'test',\n",
    "            '--output',\n",
    "            str(output_path),\n",
    "        ]\n",
    "        print('Running:', ' '.join(cmd))\n",
    "        subprocess.run(cmd, check=True)\n",
    "    else:\n",
    "        print('No checkpoints available. Train the model first.')\n",
    "\n",
    "if output_path.exists():\n",
    "    df = pd.read_csv(output_path)\n",
    "    display(df.head())\n",
    "else:\n",
    "    print('No exported recommendation outputs yet.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4423d4b1",
   "metadata": {},
   "source": [
    "---\n",
    "This notebook provides a scaffold for the BT-BERT workflow. Customize each code block as needed."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}